{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_preprocessing_data_using_huggingface.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDWVXk71sose0nl0nNBEPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahr-eddine/nlp_preprocessing_data/blob/main/nlp_preprocessing_data_using_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j7NN2nZ_qW6"
      },
      "source": [
        "## **Preprocessing data using HuggingFace package** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBa5fGEl_8_9"
      },
      "source": [
        "**Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-o-5mFi_9XM"
      },
      "source": [
        "dataset = [        \n",
        "\"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely\n",
        "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from\n",
        "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational\n",
        "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new\n",
        "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the\n",
        "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a\n",
        "way which had not happened before.\"\"\",\n",
        "\n",
        " \"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي  وهي بدايات الجبر،ومن المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن\n",
        "المفهوم اليوناني للرياضيات التي هي في جوهرها  هندسة، الجبركان نظرية موحدة تتحيح الأعداد الكسرية و الأعداد اللا كسرية ، والمقادير الهندسية و غيرها ، أن تتعامل على أنها أجسام جبرية، و أعطت الرياضيات ككل مسارا جديدًا للتطوربمفهوم \n",
        " أوسع بكثير من الذي كان موجودًا من قبل ، وقدم وسيلة للتنمية في هذا الموضوع مستقبلا .و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها \n",
        "بطريقة  لم تحدث من قبل.\"\"\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7OMQYqqDdrL"
      },
      "source": [
        "**Installing Transformers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Rj-0DXAvBk",
        "outputId": "bb921cff-157f-4063-8be4-439786d72604"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ARYBzn7DNhE"
      },
      "source": [
        "**Import packages**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_NkdnxCDTcr"
      },
      "source": [
        "**Using BERT Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-mOKyvtBt1r"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySuR8MiEC4nb"
      },
      "source": [
        "## **Begin Preprocessing** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA5oyJySC_kM"
      },
      "source": [
        "**Remove punctuations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5PPNfSyDCnF",
        "outputId": "74ada8ad-d9d1-42ae-c6e2-99e4db192dc7"
      },
      "source": [
        "import string\n",
        "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation  #all punctuations \n",
        "print(punctuations)\n",
        "\n",
        "def remove_punctuations(text):\n",
        "  my_clean_text = ''.join([item for item in text if item not in punctuations])\n",
        "  return my_clean_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1NiSWXDDFxU"
      },
      "source": [
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgj3W-2_B2aL"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME) ##import library \n",
        "\n",
        "\n",
        "def tokenize_text(text):\n",
        "  text = text.lower()\n",
        "  data = [item for item in tokenizer.tokenize(text)]\n",
        "  ids = tokenizer.convert_tokens_to_ids(data)\n",
        "  return data,ids\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W71OLJdNB_6c",
        "outputId": "28396299-d65f-42a2-a0d4-482b95fd6e13"
      },
      "source": [
        "\n",
        "tokens,ids =  tokenize_text(dataset[0])\n",
        "print(tokens , ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['perhaps', 'one', 'of', 'the', 'most', 'significant', 'advances', 'made', 'by', 'a', '##rab', '##ic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'al', '-', 'k', '##hwa', '##riz', '##mi', ',', 'namely', 'the', 'beginnings', 'of', 'algebra', '.', 'it', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'was', '.', 'it', 'was', 'a', 'revolutionary', 'move', 'away', 'from', 'the', 'g', '##ree', '##k', 'concept', 'of', 'mathematics', 'which', 'was', 'essentially', 'geometry', '.', 'algebra', 'was', 'a', 'un', '##ifying', 'theory', 'which', 'allowed', 'rational', 'numbers', ',', 'irrational', 'numbers', ',', 'geometric', '##al', 'magnitude', '##s', ',', 'etc', '.', ',', 'to', 'all', 'be', 'treated', 'as', '\"', 'algebraic', 'objects', '\"', '.', 'it', 'gave', 'mathematics', 'a', 'whole', 'new', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', ',', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', 'subject', '.', 'another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'ideas', 'was', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', 'way', 'which', 'had', 'not', 'happened', 'before', '.'] [3229, 1141, 1104, 1103, 1211, 2418, 11823, 1189, 1118, 170, 17952, 1596, 6686, 1310, 1120, 1142, 1159, 1114, 1103, 1250, 1104, 2393, 118, 180, 24156, 28021, 3080, 117, 8199, 1103, 19304, 1104, 13450, 119, 1122, 1110, 1696, 1106, 2437, 1198, 1293, 2418, 1142, 1207, 1911, 1108, 119, 1122, 1108, 170, 8953, 1815, 1283, 1121, 1103, 176, 8871, 1377, 3400, 1104, 6686, 1134, 1108, 7588, 12053, 119, 13450, 1108, 170, 8362, 8985, 2749, 1134, 2148, 12478, 2849, 117, 27447, 2849, 117, 16735, 1348, 10094, 1116, 117, 3576, 119, 117, 1106, 1155, 1129, 5165, 1112, 107, 19669, 4546, 107, 119, 1122, 1522, 6686, 170, 2006, 1207, 1718, 3507, 1177, 1277, 12594, 1107, 3400, 1106, 1115, 1134, 1125, 5131, 1196, 117, 1105, 2136, 170, 3686, 1111, 2174, 1718, 1104, 1103, 2548, 119, 1330, 1696, 7631, 1104, 1103, 4784, 1104, 19669, 4133, 1108, 1115, 1122, 2148, 6686, 1106, 1129, 3666, 1106, 2111, 1107, 170, 1236, 1134, 1125, 1136, 2171, 1196, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}